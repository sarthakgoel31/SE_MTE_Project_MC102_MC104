# SE_MTE_Project_MC102_MC104
Deep Neural Networks generally contain a lot of features. The more the features the better the classification but at the same time we must also remember that it makes the system very complex and also takes a lot of time to process. Our goal in this paper is hence going to be a way to find out how we can reduce the number of features which is called “dropping out features of over fitted networks” ,While doing this we also want to make sure that there is no information loss pertaining to it That is why we are implementing this project to make sure that we can remove unnecessary features without significant or in some cases no loss in information so we will be working on the MNIST image dataset for this to happen.
